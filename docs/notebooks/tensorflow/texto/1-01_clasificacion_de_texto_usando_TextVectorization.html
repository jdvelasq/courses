

<!DOCTYPE html>
<html class="writer-html5" lang="es" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Clasificación de texto usando TextVectorization &mdash; documentación de --- Cursos --- - </title>
  

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/copybutton.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/language_data.js"></script>
        <script src="../../../_static/clipboard.min.js"></script>
        <script src="../../../_static/copybutton.js"></script>
        <script src="../../../_static/translations.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Índice" href="../../../genindex.html" />
    <link rel="search" title="Búsqueda" href="../../../search.html" />
    <link rel="next" title="Clasificación de texto usando embeddings" href="1-02_clasificacion_de_texto_usando_embeddings.html" />
    <link rel="prev" title="Predicción de la eficiencia de combustible usando regresión con Early Stopping" href="../intro/1-02_regression.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home"> --- Cursos ---
          

          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Configuración</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../setup.html">Instalación de Vagrant y Docker</a></li>
</ul>
<p class="caption"><span class="caption-text">Cursos de Pregrado</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../fundamentos-de-analitica/index.html">Fundamentos de Analítica</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html">Redes Neuronales Artificiales y Algoritmos Bioinspirados</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-01-2021-02-23">Sesión 01 (2021-02-23)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-02-2021-03-02">Sesión 02 (2021-03-02)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-03-2021-03-09">Sesión 03 (2021-03-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-04-2021-03-16">Sesión 04 (2021-03-16)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-05-2021-03-23">Sesión 05 (2021-03-23)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-06-2021-04-06">Sesión 06 (2021-04-06)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-07-2021-04-13">Sesión 07 (2021-04-13)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-08-2021-04-20">Sesión 08 (2021-04-20)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-09-2021-04-27">Sesión 09 (2021-04-27)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-10-2021-05-04">Sesión 10 (2021-05-04)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-11-2021-07-27">Sesión 11 (2021-07-27)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-12-2021-08-03">Sesión 12 (2021-08-03)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-13-2021-08-10">Sesión 13 (2021-08-10)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-14-2021-08-17">Sesión 14 (2021-08-17)</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-15-2021-08-24">Sesión 15 (2021-08-24)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#sesion-16-2021-08-31">Sesión 16 (2021-08-31)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../redes_neuronales_y_algoritmos_bioinspirados/index.html#material-para-proximos-cursos-2022">Material para próximos cursos (2022)</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Cursos de Posgrado</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../analitica-de-grandes-datos/index.html">Analítica de Grandes Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../analitica-predictiva/index.html">Analítica Predictiva</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ciencia-de-los-datos/index.html">Ciencia de los Datos Aplicada</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../productos-de-datos/index.html">Productos de Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../analitica_avanzada/index.html">Analítica Avanzada</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">--- Cursos ---</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content style-external-links">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../../fundamentos-de-analitica/index.html">Fundamentos de Analítica</a> &raquo;</li>
        
      <li>Clasificación de texto usando TextVectorization</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../../_sources/notebooks/tensorflow/texto/1-01_clasificacion_de_texto_usando_TextVectorization.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Clasificación-de-texto-usando-TextVectorization">
<h1>Clasificación de texto usando TextVectorization<a class="headerlink" href="#Clasificación-de-texto-usando-TextVectorization" title="Enlazar permanentemente con este título">¶</a></h1>
<ul class="simple">
<li><p>30:00 min | Última modificación: Mayo 3, 2021 | [YouTube]</p></li>
</ul>
<p>Basado en:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.tensorflow.org/tutorials/keras/text_classification_with_hub">https://www.tensorflow.org/tutorials/keras/text_classification_with_hub</a></p></li>
<li><p><a class="reference external" href="https://www.tensorflow.org/tutorials/text/word_embeddings">https://www.tensorflow.org/tutorials/text/word_embeddings</a></p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">shutil</span>
<span class="kn">import</span> <span class="nn">string</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">preprocessing</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers.experimental.preprocessing</span> <span class="kn">import</span> <span class="n">TextVectorization</span>

<span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
2.4.1
</pre></div></div>
</div>
<div class="section" id="Carga-de-datos">
<h2>Carga de datos<a class="headerlink" href="#Carga-de-datos" title="Enlazar permanentemente con este título">¶</a></h2>
<p><strong>Descarga de datos en Google Colab</strong>*</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz&quot;</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">get_file</span><span class="p">(</span>
    <span class="s2">&quot;aclImdb_v1&quot;</span><span class="p">,</span>
    <span class="n">url</span><span class="p">,</span>
    <span class="n">untar</span><span class="o">=</span><span class="kc">True</span>
    <span class="n">cache_dir</span><span class="o">=</span><span class="s2">&quot;.&quot;</span><span class="p">,</span>
    <span class="n">cache_subdir</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>Descarga de datos en Terminal</strong></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz
$ tar -zxf aclImdb_v1.tar.gz
</pre></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Este es el valor devuelto por</span>
<span class="c1"># dataset_dir = os.path.join(os.path.dirname(dataset), &quot;aclImdb&quot;)</span>
<span class="c1">#</span>
<span class="n">dataset_dir</span> <span class="o">=</span> <span class="s2">&quot;./aclImdb&quot;</span>

<span class="c1">#</span>
<span class="c1"># Contenido del directorio ./aclImdb</span>
<span class="c1"># Note que los mensajes ya estan divididos en conjuntos</span>
<span class="c1"># de entrenamiento y prueba</span>
<span class="c1">#</span>
<span class="o">!</span>ls -1 <span class="o">{</span>dataset_dir<span class="o">}</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
README
imdb.vocab
imdbEr.txt
test
train
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Contenido del directorio de entrenamiento</span>
<span class="c1">#</span>
<span class="n">train_dir</span> <span class="o">=</span> <span class="n">dataset_dir</span> <span class="o">+</span>  <span class="s2">&quot;/train&quot;</span>
<span class="o">!</span>ls -1 <span class="o">{</span>train_dir<span class="o">}</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
labeledBow.feat
neg
pos
unsupBow.feat
urls_neg.txt
urls_pos.txt
urls_unsup.txt
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Ejemplo de un mensaje positivo</span>
<span class="c1">#</span>
<span class="o">!</span>cat <span class="o">{</span>train_dir + <span class="s2">&quot;/pos/1181_9.txt&quot;</span><span class="o">}</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Rachel Griffiths writes and directs this award winning short film. A heartwarming story about coping with grief and cherishing the memory of those we&#39;ve loved and lost. Although, only 15 minutes long, Griffiths manages to capture so much emotion and truth onto film in the short space of time. Bud Tingwell gives a touching performance as Will, a widower struggling to cope with his wife&#39;s death. Will is confronted by the harsh reality of loneliness and helplessness as he proceeds to take care of Ruth&#39;s pet cow, Tulip. The film displays the grief and responsibility one feels for those they have loved and lost. Good cinematography, great direction, and superbly acted. It will bring tears to all those who have lost a loved one, and survived.
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Remueve el directorio unsup</span>
<span class="c1">#</span>
<span class="o">!</span>rm -rf <span class="o">{</span>train_dir + <span class="s2">&quot;/unsup&quot;</span><span class="o">}</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">SEED</span> <span class="o">=</span> <span class="mi">42</span>

<span class="c1">#</span>
<span class="c1"># La función text_dataset_from_directory permite leer los</span>
<span class="c1"># archivos de un directorio. Usa el 80% de los datos de train</span>
<span class="c1"># para entrenamiento y el 20% restante para validación.</span>
<span class="c1"># Note que la función debe llamarse dos veces.</span>
<span class="c1">#</span>
<span class="c1"># Cada mensaje es almacenado como un archivo individual y</span>
<span class="c1"># cada directorio representa una categoria (pos/neg)</span>
<span class="c1">#</span>
<span class="c1"># Quedan tres conjuntos de datos train, test y validation</span>
<span class="c1">#</span>

<span class="n">raw_train_ds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">text_dataset_from_directory</span><span class="p">(</span>
    <span class="s2">&quot;aclImdb/train&quot;</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
    <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">subset</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">,</span>
    <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">raw_val_ds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">text_dataset_from_directory</span><span class="p">(</span>
    <span class="s2">&quot;aclImdb/train&quot;</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
    <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">subset</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1">#</span>
<span class="c1"># raw_train_ds es una tupla conformada por la lista de</span>
<span class="c1"># mensajes que conforman el batch y la lista de enteros</span>
<span class="c1"># que codifican la clase.</span>
<span class="c1">#</span>
<span class="c1">#  (</span>
<span class="c1">#    [msg1, msg2, ...]</span>
<span class="c1">#    [lbl1, lbl2, ...]</span>
<span class="c1">#  )</span>
<span class="c1">#</span>
<span class="c1"># text_batch es una lista de strings (primer batch), donde</span>
<span class="c1"># cada string es una de las revisiones.</span>
<span class="c1">#</span>
<span class="c1"># label batch es una lista de enteros {0,1} que corresponden</span>
<span class="c1"># a la categoría del mensaje.</span>
<span class="c1">#</span>
<span class="c1"># Imprime los primeros tres mensajes y su etiqueta</span>
<span class="c1"># del primer batch</span>
<span class="c1">#</span>
<span class="nb">print</span><span class="p">()</span>
<span class="k">for</span> <span class="n">text_batch</span><span class="p">,</span> <span class="n">label_batch</span> <span class="ow">in</span> <span class="n">raw_train_ds</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Review&quot;</span><span class="p">,</span> <span class="n">text_batch</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="n">i</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Label&quot;</span><span class="p">,</span> <span class="n">label_batch</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="n">i</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Found 25000 files belonging to 2 classes.
Using 20000 files for training.
Found 25000 files belonging to 2 classes.
Using 5000 files for validation.

Review b&#39;&#34;Pandemonium&#34; is a horror movie spoof that comes off more stupid than funny. Believe me when I tell you, I love comedies. Especially comedy spoofs. &#34;Airplane&#34;, &#34;The Naked Gun&#34; trilogy, &#34;Blazing Saddles&#34;, &#34;High Anxiety&#34;, and &#34;Spaceballs&#34; are some of my favorite comedies that spoof a particular genre. &#34;Pandemonium&#34; is not up there with those films. Most of the scenes in this movie had me sitting there in stunned silence because the movie wasn\&#39;t all that funny. There are a few laughs in the film, but when you watch a comedy, you expect to laugh a lot more than a few times and that\&#39;s all this film has going for it. Geez, &#34;Scream&#34; had more laughs than this film and that was more of a horror film. How bizarre is that?&lt;br /&gt;&lt;br /&gt;*1/2 (out of four)&#39;

Label 0

Review b&#34;David Mamet is a very interesting and a very un-equal director. His first movie &#39;House of Games&#39; was the one I liked best, and it set a series of films with characters whose perspective of life changes as they get into complicated situations, and so does the perspective of the viewer.&lt;br /&gt;&lt;br /&gt;So is &#39;Homicide&#39; which from the title tries to set the mind of the viewer to the usual crime drama. The principal characters are two cops, one Jewish and one Irish who deal with a racially charged area. The murder of an old Jewish shop owner who proves to be an ancient veteran of the Israeli Independence war triggers the Jewish identity in the mind and heart of the Jewish detective.&lt;br /&gt;&lt;br /&gt;This is were the flaws of the film are the more obvious. The process of awakening is theatrical and hard to believe, the group of Jewish militants is operatic, and the way the detective eventually walks to the final violent confrontation is pathetic. The end of the film itself is Mamet-like smart, but disappoints from a human emotional perspective.&lt;br /&gt;&lt;br /&gt;Joe Mantegna and William Macy give strong performances, but the flaws of the story are too evident to be easily compensated.&#34;

Label 0

Review b&#39;Great documentary about the lives of NY firefighters during the worst terrorist attack of all time.. That reason alone is why this should be a must see collectors item.. What shocked me was not only the attacks, but the&#34;High Fat Diet&#34; and physical appearance of some of these firefighters. I think a lot of Doctors would agree with me that,in the physical shape they were in, some of these firefighters would NOT of made it to the 79th floor carrying over 60 lbs of gear. Having said that i now have a greater respect for firefighters and i realize becoming a firefighter is a life altering job. The French have a history of making great documentary\&#39;s and that is what this is, a Great Documentary.....&#39;

Label 1

</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Categorias</span>
<span class="c1">#</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">raw_train_ds</span><span class="o">.</span><span class="n">class_names</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0 neg
1 pos
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Lee los mensajes del grupo de testing</span>
<span class="c1">#</span>
<span class="n">raw_test_ds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">text_dataset_from_directory</span><span class="p">(</span>
    <span class="s2">&quot;aclImdb/test&quot;</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Found 25000 files belonging to 2 classes.
</pre></div></div>
</div>
</div>
<div class="section" id="Representación-de-texto-usando-One-Hot-encoding-o-Document-Term-Matrix">
<h2>Representación de texto usando One-Hot encoding o Document-Term-Matrix<a class="headerlink" href="#Representación-de-texto-usando-One-Hot-encoding-o-Document-Term-Matrix" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Considere la siguientes frases: “Hola mundo cruel”, “El mundo es cruel”.</p>
<p>Es ineficiente porque genera una matriz que tiene la mayor parte de sus términos iguales a cero.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>        Hola  mundo  cruel    El   es

msg 1      1      1      1     0    0

msg 2      0      1      1     1    1
</pre></div>
</div>
</div>
<div class="section" id="Codificación-de-cada-palabra-como-un-entero-único">
<h2>Codificación de cada palabra como un entero único<a class="headerlink" href="#Codificación-de-cada-palabra-como-un-entero-único" title="Enlazar permanentemente con este título">¶</a></h2>
<p>La codificación como enteros es arbitraria y no captura las relaciones entre palabras.</p>
<p>Es muy dificil interpretar el modelo resultante.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Hola:  1
mundo: 2
cruel: 3
El:    4
es:    5


msg1: [1, 2, 3]
msg2: [4, 2, 5, 3]
</pre></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">tv</span> <span class="o">=</span> <span class="n">TextVectorization</span><span class="p">(</span>
    <span class="n">max_tokens</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>             <span class="c1"># tamaño del vocabulario (palabras + &#39;&#39; + [UKNOWN])</span>
    <span class="n">output_mode</span><span class="o">=</span><span class="s2">&quot;int&quot;</span><span class="p">,</span>        <span class="c1"># enteros</span>
    <span class="n">output_sequence_length</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="c1"># numero de palabras por frase</span>
<span class="p">)</span>

<span class="n">tv</span><span class="o">.</span><span class="n">adapt</span><span class="p">(</span>
    <span class="p">[</span><span class="s2">&quot;Hola mundo cruel&quot;</span><span class="p">,</span> <span class="s2">&quot;El mundo es cruel&quot;</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">tv</span><span class="o">.</span><span class="n">get_vocabulary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&#39;&#39;, &#39;[UNK]&#39;, &#39;mundo&#39;, &#39;cruel&#39;, &#39;hola&#39;, &#39;es&#39;, &#39;el&#39;]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">tv</span><span class="p">([</span><span class="s2">&quot;Hola mundo cruel&quot;</span><span class="p">,</span> <span class="s2">&quot;El mundo es cruel&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([[4, 2, 3, 0],
       [6, 2, 5, 3]])
</pre></div></div>
</div>
</div>
<div class="section" id="Representación-de-palabras-usando-Embedding">
<h2>Representación de palabras usando Embedding<a class="headerlink" href="#Representación-de-palabras-usando-Embedding" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Cada palabra es representada por un vector de números reales de n dimensiones, en el que palabras similares tienen una representación similar, y los cuales pueden capturar relaciones entre palabras. Esta es una matriz de la forma</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>         dim_0  dim_1  dim_2
word_0      .       .      .
word_1      .       .      .
word_2      .       .      .
...         .       .      .
</pre></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># El siguiente codigo crea una capa con un</span>
<span class="c1"># vocabulario de 1000 palabras y 5 dimenciones</span>
<span class="c1">#</span>
<span class="n">embedding_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

<span class="c1">#</span>
<span class="c1"># Representación un vector de palabras (frase)</span>
<span class="c1"># como un embeding</span>
<span class="c1">#</span>
<span class="n">embedding_layer</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">8</span><span class="p">]))</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([[ 0.01094563,  0.0473342 ,  0.00087859, -0.02028556, -0.04986701],
       [ 0.01094563,  0.0473342 ,  0.00087859, -0.02028556, -0.04986701],
       [-0.02175917,  0.03644494,  0.04551655,  0.0337589 ,  0.01326085],
       [-0.02706339,  0.0217892 ,  0.04538036, -0.00362183,  0.03315837],
       [-0.00910066,  0.02574174, -0.00987263,  0.00827517,  0.00640567],
       [-0.00885882,  0.03003721,  0.04184267, -0.02155001,  0.01038473]],
      dtype=float32)
</pre></div></div>
</div>
<p>Si una frase (vector de enteros) se representa como una matriz de dos dimensiones, entonces una lista de frases se representa como una lista de matrices de dos dimensiones</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>[
  msg_0
  msg_1
  ...
]

[
  embedding_0
  embedding_1
  ...
]
</pre></div>
</div>
</div>
<div class="section" id="Capas-GlobalAveragePooling1D">
<h2>Capas GlobalAveragePooling1D<a class="headerlink" href="#Capas-GlobalAveragePooling1D" title="Enlazar permanentemente con este título">¶</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Se tienen dos (2) frases, cada una con tres (3)</span>
<span class="c1"># palabras, las cuales son representadas por</span>
<span class="c1"># embeddings de cuatro (4) dimensiones.</span>
<span class="c1">#</span>
<span class="c1"># Se genera un tensor aleatorio para representar</span>
<span class="c1"># el embedding</span>
<span class="c1">#</span>
<span class="n">emb</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">emb</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([[[-0.711405  ,  0.82804507, -0.6800134 ,  0.61349636],
        [ 0.63947314, -0.8410555 , -0.89209867,  1.5784249 ],
        [-0.44384128, -0.28291616, -0.32439324, -1.6501985 ]],

       [[ 0.2521129 , -1.6494555 , -0.80866116, -1.7723985 ],
        [-0.10332082, -0.6485718 , -0.5244544 , -2.1529558 ],
        [-0.74567974, -0.13720043, -1.336586  ,  0.25070038]]],
      dtype=float32)
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># La capa GlobalAveragePooling1D computa el promedio</span>
<span class="c1"># de cada dimension sobre las palabras. De esta forma</span>
<span class="c1"># cada frase es representada por un vector que tiene</span>
<span class="c1"># las mismas dimensiones del embedding</span>
<span class="c1">#</span>
<span class="n">layers</span><span class="o">.</span><span class="n">GlobalAveragePooling1D</span><span class="p">()(</span><span class="n">emb</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;tf.Tensor: shape=(2, 4), dtype=float32, numpy=
array([[-0.17192437, -0.0986422 , -0.6321685 ,  0.18057425],
       [-0.19896255, -0.81174254, -0.8899005 , -1.2248846 ]],
      dtype=float32)&gt;
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Eiemplo para la primera dimension de la primera frase</span>
<span class="c1">#</span>
<span class="nb">sum</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="mf">0.6626813</span><span class="p">,</span>
        <span class="mf">0.24296597</span><span class="p">,</span>
        <span class="mf">0.49586588</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">)</span> <span class="o">/</span> <span class="mi">3</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0.46717105
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Eiemplo para la segunda dimension de la segunda frase</span>
<span class="c1">#</span>
<span class="nb">sum</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="mf">0.03367105</span><span class="p">,</span>
        <span class="mf">0.5818733</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">1.6331478</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">)</span> <span class="o">/</span> <span class="mi">3</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
-0.3392011499999999
</pre></div></div>
</div>
</div>
<div class="section" id="Preprocesamiento-de-texto">
<h2>Preprocesamiento de texto<a class="headerlink" href="#Preprocesamiento-de-texto" title="Enlazar permanentemente con este título">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># De los mensajes de ejemplo impresos anteriormente, se</span>
<span class="c1"># observa la presencia de la cadena HTML &lt;br /&gt; en</span>
<span class="c1"># algunos de ellos.</span>
<span class="c1">#</span>
<span class="c1"># Se crea una preprocesador personalizado para</span>
<span class="c1"># transformar a minusculas, eliminar &lt;br /&gt;,</span>
<span class="c1"># y eliminar signos de puntuación</span>
<span class="c1">#</span>
<span class="k">def</span> <span class="nf">custom_standardization</span><span class="p">(</span><span class="n">input_data</span><span class="p">):</span>

    <span class="n">lowercase</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">strings</span><span class="o">.</span><span class="n">lower</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>

    <span class="n">stripped_html</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">strings</span><span class="o">.</span><span class="n">regex_replace</span><span class="p">(</span>
        <span class="n">lowercase</span><span class="p">,</span>
        <span class="s2">&quot;&lt;br /&gt;&quot;</span><span class="p">,</span>
        <span class="s2">&quot; &quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">strings</span><span class="o">.</span><span class="n">regex_replace</span><span class="p">(</span>
        <span class="n">stripped_html</span><span class="p">,</span>
        <span class="s2">&quot;[</span><span class="si">%s</span><span class="s2">]&quot;</span> <span class="o">%</span> <span class="n">re</span><span class="o">.</span><span class="n">escape</span><span class="p">(</span><span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">),</span>
        <span class="s2">&quot;&quot;</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">MAX_FEATURES</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">SEQUENCE_LENGTH</span> <span class="o">=</span> <span class="mi">250</span>

<span class="n">vectorize_layer</span> <span class="o">=</span> <span class="n">TextVectorization</span><span class="p">(</span>
    <span class="n">standardize</span><span class="o">=</span><span class="n">custom_standardization</span><span class="p">,</span>
    <span class="n">max_tokens</span><span class="o">=</span><span class="n">MAX_FEATURES</span><span class="p">,</span>
    <span class="n">output_mode</span><span class="o">=</span><span class="s2">&quot;int&quot;</span><span class="p">,</span>
    <span class="n">output_sequence_length</span><span class="o">=</span><span class="n">SEQUENCE_LENGTH</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1">#</span>
<span class="c1"># Recuerde que raw_train_ds y raw_val_ds son tuplas</span>
<span class="c1"># conformada por la lista de mensajes que conforman</span>
<span class="c1"># el batch y la lista de enteros que codifican la clase.</span>
<span class="c1">#</span>
<span class="c1">#  (</span>
<span class="c1">#    [msg1, msg2, ...]</span>
<span class="c1">#    [lbl1, lbl2, ...]</span>
<span class="c1">#  )</span>
<span class="c1">#</span>
<span class="c1"># La llamada a map extrae unicamente la componente del</span>
<span class="c1"># mensaje</span>
<span class="c1">#</span>
<span class="n">train_text</span> <span class="o">=</span> <span class="n">raw_train_ds</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">x</span><span class="p">)</span>

<span class="c1">#</span>
<span class="c1"># Llama al objeto construido con TextVectorization</span>
<span class="c1"># y lo adapta. Genera la representación de las</span>
<span class="c1"># palabras como un entero único. Cada frase es</span>
<span class="c1"># una secuencia de enteros.</span>
<span class="c1">#</span>
<span class="n">vectorize_layer</span><span class="o">.</span><span class="n">adapt</span><span class="p">(</span><span class="n">train_text</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Se cambia la propiedad shape del Tensor</span>
<span class="c1"># para poder procesarlo. La función retorna</span>
<span class="c1"># una tupla</span>
<span class="c1">#</span>
<span class="k">def</span> <span class="nf">vectorize_text</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">vectorize_layer</span><span class="p">(</span><span class="n">text</span><span class="p">),</span> <span class="n">label</span>

<span class="c1">#</span>
<span class="c1"># Obtiene el primer batch del dataset de entrenamiento</span>
<span class="c1">#</span>
<span class="n">text_batch</span><span class="p">,</span> <span class="n">label_batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">raw_train_ds</span><span class="p">))</span>

<span class="c1">#</span>
<span class="c1"># Extrae la primera revision.</span>
<span class="c1">#</span>
<span class="n">first_review</span><span class="p">,</span> <span class="n">first_label</span> <span class="o">=</span> <span class="n">text_batch</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">label_batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Review&quot;</span><span class="p">,</span> <span class="n">first_review</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Review&quot;</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">first_review</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Label&quot;</span><span class="p">,</span> <span class="n">raw_train_ds</span><span class="o">.</span><span class="n">class_names</span><span class="p">[</span><span class="n">first_label</span><span class="p">])</span>
<span class="nb">print</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Review tf.Tensor(b&#39;Silent Night, Deadly Night 5 is the very last of the series, and like part 4, it\&#39;s unrelated to the first three except by title and the fact that it\&#39;s a Christmas-themed horror flick.&lt;br /&gt;&lt;br /&gt;Except to the oblivious, there\&#39;s some obvious things going on here...Mickey Rooney plays a toymaker named Joe Petto and his creepy son\&#39;s name is Pino. Ring a bell, anyone? Now, a little boy named Derek heard a knock at the door one evening, and opened it to find a present on the doorstep for him. Even though it said &#34;don\&#39;t open till Christmas&#34;, he begins to open it anyway but is stopped by his dad, who scolds him and sends him to bed, and opens the gift himself. Inside is a little red ball that sprouts Santa arms and a head, and proceeds to kill dad. Oops, maybe he should have left well-enough alone. Of course Derek is then traumatized by the incident since he watched it from the stairs, but he doesn\&#39;t grow up to be some killer Santa, he just stops talking.&lt;br /&gt;&lt;br /&gt;There\&#39;s a mysterious stranger lurking around, who seems very interested in the toys that Joe Petto makes. We even see him buying a bunch when Derek\&#39;s mom takes him to the store to find a gift for him to bring him out of his trauma. And what exactly is this guy doing? Well, we\&#39;re not sure but he does seem to be taking these toys apart to see what makes them tick. He does keep his landlord from evicting him by promising him to pay him in cash the next day and presents him with a &#34;Larry the Larvae&#34; toy for his kid, but of course &#34;Larry&#34; is not a good toy and gets out of the box in the car and of course, well, things aren\&#39;t pretty.&lt;br /&gt;&lt;br /&gt;Anyway, eventually what\&#39;s going on with Joe Petto and Pino is of course revealed, and as with the old story, Pino is not a &#34;real boy&#34;. Pino is probably even more agitated and naughty because he suffers from &#34;Kenitalia&#34; (a smooth plastic crotch) so that could account for his evil ways. And the identity of the lurking stranger is revealed too, and there\&#39;s even kind of a happy ending of sorts. Whee.&lt;br /&gt;&lt;br /&gt;A step up from part 4, but not much of one. Again, Brian Yuzna is involved, and Screaming Mad George, so some decent special effects, but not enough to make this great. A few leftovers from part 4 are hanging around too, like Clint Howard and Neith Hunter, but that doesn\&#39;t really make any difference. Anyway, I now have seeing the whole series out of my system. Now if I could get some of it out of my brain. 4 out of 5.&#39;, shape=(), dtype=string)

Review tf.Tensor([b&#39;Silent Night, Deadly Night 5 is the very last of the series, and like part 4, it\&#39;s unrelated to the first three except by title and the fact that it\&#39;s a Christmas-themed horror flick.&lt;br /&gt;&lt;br /&gt;Except to the oblivious, there\&#39;s some obvious things going on here...Mickey Rooney plays a toymaker named Joe Petto and his creepy son\&#39;s name is Pino. Ring a bell, anyone? Now, a little boy named Derek heard a knock at the door one evening, and opened it to find a present on the doorstep for him. Even though it said &#34;don\&#39;t open till Christmas&#34;, he begins to open it anyway but is stopped by his dad, who scolds him and sends him to bed, and opens the gift himself. Inside is a little red ball that sprouts Santa arms and a head, and proceeds to kill dad. Oops, maybe he should have left well-enough alone. Of course Derek is then traumatized by the incident since he watched it from the stairs, but he doesn\&#39;t grow up to be some killer Santa, he just stops talking.&lt;br /&gt;&lt;br /&gt;There\&#39;s a mysterious stranger lurking around, who seems very interested in the toys that Joe Petto makes. We even see him buying a bunch when Derek\&#39;s mom takes him to the store to find a gift for him to bring him out of his trauma. And what exactly is this guy doing? Well, we\&#39;re not sure but he does seem to be taking these toys apart to see what makes them tick. He does keep his landlord from evicting him by promising him to pay him in cash the next day and presents him with a &#34;Larry the Larvae&#34; toy for his kid, but of course &#34;Larry&#34; is not a good toy and gets out of the box in the car and of course, well, things aren\&#39;t pretty.&lt;br /&gt;&lt;br /&gt;Anyway, eventually what\&#39;s going on with Joe Petto and Pino is of course revealed, and as with the old story, Pino is not a &#34;real boy&#34;. Pino is probably even more agitated and naughty because he suffers from &#34;Kenitalia&#34; (a smooth plastic crotch) so that could account for his evil ways. And the identity of the lurking stranger is revealed too, and there\&#39;s even kind of a happy ending of sorts. Whee.&lt;br /&gt;&lt;br /&gt;A step up from part 4, but not much of one. Again, Brian Yuzna is involved, and Screaming Mad George, so some decent special effects, but not enough to make this great. A few leftovers from part 4 are hanging around too, like Clint Howard and Neith Hunter, but that doesn\&#39;t really make any difference. Anyway, I now have seeing the whole series out of my system. Now if I could get some of it out of my brain. 4 out of 5.&#39;], shape=(1,), dtype=string)

Label neg

</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Note que el vector tiene SEQUENCE_LENGTH=250 posiciones</span>
<span class="c1">#</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Vectorized review&quot;</span><span class="p">,</span> <span class="n">vectorize_text</span><span class="p">(</span><span class="n">first_review</span><span class="p">,</span> <span class="n">first_label</span><span class="p">))</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;1287 ---&gt; &quot;</span><span class="p">,</span> <span class="n">vectorize_layer</span><span class="o">.</span><span class="n">get_vocabulary</span><span class="p">()[</span><span class="mi">1287</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot; 313 ---&gt; &quot;</span><span class="p">,</span> <span class="n">vectorize_layer</span><span class="o">.</span><span class="n">get_vocabulary</span><span class="p">()[</span><span class="mi">313</span><span class="p">])</span>
<span class="nb">print</span><span class="p">()</span>

<span class="c1">#</span>
<span class="c1"># Note que el vocabulario tiene un tamaño MAX_FEATURES = 10000</span>
<span class="c1">#</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Vocabulary size: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vectorize_layer</span><span class="o">.</span><span class="n">get_vocabulary</span><span class="p">())))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Vectorized review (&lt;tf.Tensor: shape=(1, 250), dtype=int64, numpy=
array([[1287,  313, 2380,  313,  661,    7,    2,   52,  229,    5,    2,
         200,    3,   38,  170,  669,   29, 5492,    6,    2,   83,  297,
         549,   32,  410,    3,    2,  186,   12,   29,    4,    1,  191,
         510,  549,    6,    2, 8229,  212,   46,  576,  175,  168,   20,
           1, 5361,  290,    4,    1,  761,  969,    1,    3,   24,  935,
        2271,  393,    7,    1, 1675,    4, 3747,  250,  148,    4,  112,
         436,  761, 3529,  548,    4, 3633,   31,    2, 1331,   28, 2096,
           3, 2912,    9,    6,  163,    4, 1006,   20,    2,    1,   15,
          85,   53,  147,    9,  292,   89,  959, 2314,  984,   27,  762,
           6,  959,    9,  564,   18,    7, 2140,   32,   24, 1254,   36,
           1,   85,    3, 3298,   85,    6, 1410,    3, 1936,    2, 3408,
         301,  965,    7,    4,  112,  740, 1977,   12,    1, 2014, 2772,
           3,    4,  428,    3, 5177,    6,  512, 1254,    1,  278,   27,
         139,   25,  308,    1,  579,    5,  259, 3529,    7,   92, 8981,
          32,    2, 3842,  230,   27,  289,    9,   35,    2, 5712,   18,
          27,  144, 2166,   56,    6,   26,   46,  466, 2014,   27,   40,
        2745,  657,  212,    4, 1376, 3002, 7080,  183,   36,  180,   52,
         920,    8,    2, 4028,   12,  969,    1,  158,   71,   53,   67,
          85, 2754,    4,  734,   51,    1, 1611,  294,   85,    6,    2,
        1164,    6,  163,    4, 3408,   15,   85,    6,  717,   85,   44,
           5,   24, 7158,    3,   48,  604,    7,   11,  225,  384,   73,
          65,   21,  242,   18,   27,  120,  295,    6,   26,  667,  129,
        4028,  948,    6,   67,   48,  158,   93,    1]])&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=0&gt;)

1287 ---&gt;  silent
 313 ---&gt;  night

Vocabulary size: 10000
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Primeras 200 palabras del vocabulario</span>
<span class="c1">#</span>
<span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">vectorize_layer</span><span class="o">.</span><span class="n">get_vocabulary</span><span class="p">()[:</span><span class="mi">200</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&#39; [UNK] the and a of to is in it i this that was as for with movie but film on not you are his have be he one its all at by an they from who so like her just or about has out if some there what good more when very even my she up no time would which only really story their were had see can me than we much well been get will also other people bad into do first because him great how most dont made movies then them films way make any could too characters after think watch two seen character many being acting never plot little best where love life did know show does ever better your end still over off here these man say while why scene such scenes go something should through im back those doesnt real watching though now years thing actors didnt before another nothing new actually makes work funny old look find same every few us going again part lot director cast cant things quite thats want pretty seems young world around got down fact enough between however take horror both give may ive own thought original big&#39;
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Ultimas 200 palabras del vocabulario. Note que hay</span>
<span class="c1"># incluidas STOPWORDS y numeros</span>
<span class="c1">#</span>
<span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">vectorize_layer</span><span class="o">.</span><span class="n">get_vocabulary</span><span class="p">()[</span><span class="o">-</span><span class="mi">200</span><span class="p">:])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&#39;irs interpreted interpret intends integral insignificant insecure inducing illustrates illiterate ideology identified housing honorable hmmm historian hesitation heritage hector harp hardships hardest happier hamiltons hagen habits grams gossip goo gamut fulfill foxes fosters flipping flea finnish figuring feinstone featurette expressive evolve eustache ethics epps eponymous enhances empathize emerged elliot elegance eggs dripped downward documents distributors disservice directorwriter digress differ desolate dense dench demonstration december danced cynicism cues crowe crop crook cousins costuming coping convicts consisting conroy connects conduct complains commando coen cloud closes climatic cleaner chat chamberlains catalog casted canvas cages bury bureau bucket broderick brock brit brink boyish boxes bloodshed bloke blinded blending blaine binoche billion bigfoot bets bens benny beetle bathtub bathing barbarian balcony babysitter atwill attributed astonished associates ashraf aptly approximately apologies aplomb answering allegory alienation alba alamo actorsactresses abbott 64 500 43 1938 zoo zhang yea wyoming wray worm woeful witherspoon weisz weirdo wee waving warnings virtue vh1 vault uneducated undeveloped unbearably turgid travelling transvestite transported tragically townspeople toes todesking sweetheart suspicions surrounds superpowers suite subtleties subconscious struggled strips streisands stir staple stalwart spoton sparse sorvino sophomoric soooo smoothly smarmy slut skimpy skeleton singin shudder shoestring sherry sheila shawshank shamelessly seinfeld segal scenic sarne sabu rushes&#39;
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Aplica TextVectorize a los tres conjuntos</span>
<span class="c1"># de datos</span>
<span class="c1">#</span>
<span class="n">train_ds</span> <span class="o">=</span> <span class="n">raw_train_ds</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">vectorize_text</span><span class="p">)</span>
<span class="n">val_ds</span> <span class="o">=</span> <span class="n">raw_val_ds</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">vectorize_text</span><span class="p">)</span>
<span class="n">test_ds</span> <span class="o">=</span> <span class="n">raw_test_ds</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">vectorize_text</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Optimiza el desempeño</span>
<span class="c1">#</span>
<span class="n">AUTOTUNE</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">AUTOTUNE</span>

<span class="n">train_ds</span> <span class="o">=</span> <span class="n">train_ds</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">AUTOTUNE</span><span class="p">)</span>
<span class="n">val_ds</span> <span class="o">=</span> <span class="n">val_ds</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">AUTOTUNE</span><span class="p">)</span>
<span class="n">test_ds</span> <span class="o">=</span> <span class="n">test_ds</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">AUTOTUNE</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Modelo-inicial">
<h2>Modelo inicial<a class="headerlink" href="#Modelo-inicial" title="Enlazar permanentemente con este título">¶</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Define un embedding de 16 dimensiones</span>
<span class="c1">#</span>
<span class="n">EMBEDDING_DIM</span> <span class="o">=</span> <span class="mi">16</span>

<span class="n">model_0</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="c1">#</span>
        <span class="c1"># Embedding es una capa que contiene el vocabulario</span>
        <span class="c1"># en las filas y la cantidad de dimensiones del embedding</span>
        <span class="c1"># en las columnas. Convierte cada palabra a un vector</span>
        <span class="c1"># de reales de EMBEDDING_DIM dimensiones.</span>
        <span class="c1">#</span>
        <span class="c1"># Esta capa es inicializada aleatoriamente, y sus valores</span>
        <span class="c1"># son ajustados usando backpropagation</span>
        <span class="c1">#</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">MAX_FEATURES</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">EMBEDDING_DIM</span><span class="p">),</span>

        <span class="c1">#</span>
        <span class="c1"># Esta capa promedia cada dimension a lo larga de</span>
        <span class="c1"># las palabras que la componen. La salida es un</span>
        <span class="c1"># vector de EMBEDDING_DIM posiciones</span>
        <span class="c1">#</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">GlobalAveragePooling1D</span><span class="p">(),</span>

        <span class="c1">#</span>
        <span class="c1"># Especifica una capa densa de una sola neurona con</span>
        <span class="c1"># activación lineal a(x) = x</span>
        <span class="c1">#</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">model_0</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;sequential&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
embedding_1 (Embedding)      (None, None, 16)          160016
_________________________________________________________________
global_average_pooling1d_1 ( (None, 16)                0
_________________________________________________________________
dense (Dense)                (None, 1)                 17
=================================================================
Total params: 160,033
Trainable params: 160,033
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">model_0</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>

    <span class="c1">#</span>
    <span class="c1"># Entropia cruzada binaria</span>
    <span class="c1">#</span>
    <span class="n">loss</span><span class="o">=</span><span class="n">losses</span><span class="o">.</span><span class="n">BinaryCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>

    <span class="c1">#</span>
    <span class="c1"># Algoritmo de Adam (gradiente)</span>
    <span class="c1">#</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span>

    <span class="c1">#</span>
    <span class="c1"># Retorna el porcentaje de veces que y_pred es True</span>
    <span class="c1"># threshold representa el limite para decidir si un</span>
    <span class="c1"># valor pronosticado es 0 o 1</span>
    <span class="c1">#</span>
    <span class="n">metrics</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">BinaryAccuracy</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="mf">0.0</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">20</span>

<span class="n">history_0</span> <span class="o">=</span> <span class="n">model_0</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">train_ds</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="n">val_ds</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Epoch 1/20
625/625 [==============================] - 21s 32ms/step - loss: 0.6795 - binary_accuracy: 0.6223 - val_loss: 0.5986 - val_binary_accuracy: 0.7796
Epoch 2/20
625/625 [==============================] - 2s 3ms/step - loss: 0.5595 - binary_accuracy: 0.7955 - val_loss: 0.4750 - val_binary_accuracy: 0.8294
Epoch 3/20
625/625 [==============================] - 2s 3ms/step - loss: 0.4397 - binary_accuracy: 0.8460 - val_loss: 0.3994 - val_binary_accuracy: 0.8546
Epoch 4/20
625/625 [==============================] - 2s 3ms/step - loss: 0.3665 - binary_accuracy: 0.8686 - val_loss: 0.3571 - val_binary_accuracy: 0.8652
Epoch 5/20
625/625 [==============================] - 2s 3ms/step - loss: 0.3211 - binary_accuracy: 0.8826 - val_loss: 0.3315 - val_binary_accuracy: 0.8722
Epoch 6/20
625/625 [==============================] - 2s 3ms/step - loss: 0.2894 - binary_accuracy: 0.8939 - val_loss: 0.3148 - val_binary_accuracy: 0.8742
Epoch 7/20
625/625 [==============================] - 2s 3ms/step - loss: 0.2650 - binary_accuracy: 0.9032 - val_loss: 0.3035 - val_binary_accuracy: 0.8754
Epoch 8/20
625/625 [==============================] - 2s 3ms/step - loss: 0.2452 - binary_accuracy: 0.9111 - val_loss: 0.2959 - val_binary_accuracy: 0.8778
Epoch 9/20
625/625 [==============================] - 2s 3ms/step - loss: 0.2283 - binary_accuracy: 0.9185 - val_loss: 0.2908 - val_binary_accuracy: 0.8778
Epoch 10/20
625/625 [==============================] - 2s 3ms/step - loss: 0.2137 - binary_accuracy: 0.9232 - val_loss: 0.2878 - val_binary_accuracy: 0.8812
Epoch 11/20
625/625 [==============================] - 2s 3ms/step - loss: 0.2006 - binary_accuracy: 0.9279 - val_loss: 0.2863 - val_binary_accuracy: 0.8806
Epoch 12/20
625/625 [==============================] - 2s 3ms/step - loss: 0.1887 - binary_accuracy: 0.9343 - val_loss: 0.2861 - val_binary_accuracy: 0.8812
Epoch 13/20
625/625 [==============================] - 2s 3ms/step - loss: 0.1778 - binary_accuracy: 0.9384 - val_loss: 0.2870 - val_binary_accuracy: 0.8816
Epoch 14/20
625/625 [==============================] - 2s 3ms/step - loss: 0.1677 - binary_accuracy: 0.9423 - val_loss: 0.2888 - val_binary_accuracy: 0.8846
Epoch 15/20
625/625 [==============================] - 2s 3ms/step - loss: 0.1584 - binary_accuracy: 0.9460 - val_loss: 0.2914 - val_binary_accuracy: 0.8836
Epoch 16/20
625/625 [==============================] - 2s 3ms/step - loss: 0.1497 - binary_accuracy: 0.9492 - val_loss: 0.2948 - val_binary_accuracy: 0.8826
Epoch 17/20
625/625 [==============================] - 2s 3ms/step - loss: 0.1415 - binary_accuracy: 0.9537 - val_loss: 0.2989 - val_binary_accuracy: 0.8814
Epoch 18/20
625/625 [==============================] - 2s 3ms/step - loss: 0.1338 - binary_accuracy: 0.9563 - val_loss: 0.3035 - val_binary_accuracy: 0.8804
Epoch 19/20
625/625 [==============================] - 2s 3ms/step - loss: 0.1265 - binary_accuracy: 0.9587 - val_loss: 0.3087 - val_binary_accuracy: 0.8798
Epoch 20/20
625/625 [==============================] - 2s 3ms/step - loss: 0.1196 - binary_accuracy: 0.9616 - val_loss: 0.3145 - val_binary_accuracy: 0.8806
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span> <span class="o">=</span> <span class="n">model_0</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">train_ds</span><span class="p">)</span>
<span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
625/625 [==============================] - 1s 1ms/step - loss: 0.1099 - binary_accuracy: 0.9669
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(0.10985327512025833, 0.966949999332428)
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span> <span class="o">=</span> <span class="n">model_0</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_ds</span><span class="p">)</span>
<span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
782/782 [==============================] - 19s 23ms/step - loss: 0.3562 - binary_accuracy: 0.8643
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(0.35619601607322693, 0.8643199801445007)
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">history_dict_0</span> <span class="o">=</span> <span class="n">history_0</span><span class="o">.</span><span class="n">history</span>
<span class="n">history_dict_0</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
dict_keys([&#39;loss&#39;, &#39;binary_accuracy&#39;, &#39;val_loss&#39;, &#39;val_binary_accuracy&#39;])
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">plot_history</span><span class="p">(</span><span class="n">history_dict</span><span class="p">):</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="n">history_dict</span><span class="p">[</span><span class="s2">&quot;binary_accuracy&quot;</span><span class="p">]</span>
    <span class="n">val_acc</span> <span class="o">=</span> <span class="n">history_dict</span><span class="p">[</span><span class="s2">&quot;val_binary_accuracy&quot;</span><span class="p">]</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">history_dict</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span>
    <span class="n">val_loss</span> <span class="o">=</span> <span class="n">history_dict</span><span class="p">[</span><span class="s2">&quot;val_loss&quot;</span><span class="p">]</span>

    <span class="n">epochs</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">acc</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="s2">&quot;ko&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training loss&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Validation loss&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Training and validation loss&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epochs&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="s2">&quot;ko&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training acc&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_acc</span><span class="p">,</span> <span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Validation acc&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Training and validation accuracy&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epochs&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="n">plot_history</span><span class="p">(</span><span class="n">history_dict_0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../_images/notebooks_tensorflow_texto_1-01_clasificacion_de_texto_usando_TextVectorization_43_0.png" src="../../../_images/notebooks_tensorflow_texto_1-01_clasificacion_de_texto_usando_TextVectorization_43_0.png" />
</div>
</div>
</div>
<div class="section" id="Modelo-con-regularización">
<h2>Modelo con regularización<a class="headerlink" href="#Modelo-con-regularización" title="Enlazar permanentemente con este título">¶</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[31]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">model_1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="c1">#</span>
        <span class="c1"># Dropout aleatoriamente fija las entradas en cero con</span>
        <span class="c1"># una frecuencia dada por rate, con el fin de prevenir</span>
        <span class="c1"># el sobre-entrenamiento. Las entradas que no son fijas</span>
        <span class="c1"># en 0 se multiplican por 1 / (1 - rate) para que la</span>
        <span class="c1"># suma sobre todas las entradas permanezca igual</span>
        <span class="c1">#</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">MAX_FEATURES</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">EMBEDDING_DIM</span><span class="p">),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="mf">0.2</span><span class="p">),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">GlobalAveragePooling1D</span><span class="p">(),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="mf">0.2</span><span class="p">),</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">model_1</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;sequential_1&#34;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
embedding_2 (Embedding)      (None, None, 16)          160016
_________________________________________________________________
dropout (Dropout)            (None, None, 16)          0
_________________________________________________________________
global_average_pooling1d_2 ( (None, 16)                0
_________________________________________________________________
dropout_1 (Dropout)          (None, 16)                0
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 17
=================================================================
Total params: 160,033
Trainable params: 160,033
Non-trainable params: 0
_________________________________________________________________
</pre></div></div>
</div>
</div>
<div class="section" id="Ejemplo-Dropout">
<h2>Ejemplo Dropout<a class="headerlink" href="#Ejemplo-Dropout" title="Enlazar permanentemente con este título">¶</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[32]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1">#</span>
<span class="c1"># Semilla del generador de aleatorios</span>
<span class="c1">#</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1">#</span>
<span class="c1"># Crea una capa con dropout y salida g(x) = x</span>
<span class="c1">#</span>
<span class="n">layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">.2</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,))</span>

<span class="c1">#</span>
<span class="c1"># Datos de entrada</span>
<span class="c1">#</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">data</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[32]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([[0., 1.],
       [2., 3.],
       [4., 5.],
       [6., 7.],
       [8., 9.]], dtype=float32)
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[33]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Salida de la capa sin dropout</span>
<span class="c1">#</span>
<span class="n">layer</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[33]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;tf.Tensor: shape=(5, 2), dtype=float32, numpy=
array([[0., 1.],
       [2., 3.],
       [4., 5.],
       [6., 7.],
       [8., 9.]], dtype=float32)&gt;
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[34]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Salida de la capa con dropout.</span>
<span class="c1"># Los pesos son multiplicados por</span>
<span class="c1">#</span>
<span class="c1"># 1 / (1 - rate) = 1 / 0.8 = 1.25</span>
<span class="c1">#</span>
<span class="n">layer</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[34]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;tf.Tensor: shape=(5, 2), dtype=float32, numpy=
array([[ 0.  ,  1.25],
       [ 2.5 ,  3.75],
       [ 5.  ,  6.25],
       [ 7.5 ,  8.75],
       [10.  ,  0.  ]], dtype=float32)&gt;
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[35]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Una nueva llamada cambia las entradas</span>
<span class="c1"># llevadas a cero</span>
<span class="c1">#</span>
<span class="n">layer</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[35]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;tf.Tensor: shape=(5, 2), dtype=float32, numpy=
array([[ 0.  ,  1.25],
       [ 2.5 ,  3.75],
       [ 5.  ,  6.25],
       [ 0.  ,  8.75],
       [10.  , 11.25]], dtype=float32)&gt;
</pre></div></div>
</div>
</div>
<div class="section" id="Compilación-del-modelo">
<h2>Compilación del modelo<a class="headerlink" href="#Compilación-del-modelo" title="Enlazar permanentemente con este título">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[36]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">model_1</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
    <span class="n">loss</span><span class="o">=</span><span class="n">losses</span><span class="o">.</span><span class="n">BinaryCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">BinaryAccuracy</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="mf">0.0</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[37]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">history_1</span> <span class="o">=</span> <span class="n">model_1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">train_ds</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="n">val_ds</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Epoch 1/20
625/625 [==============================] - 3s 4ms/step - loss: 0.6824 - binary_accuracy: 0.6090 - val_loss: 0.6156 - val_binary_accuracy: 0.7720
Epoch 2/20
625/625 [==============================] - 3s 4ms/step - loss: 0.5803 - binary_accuracy: 0.7827 - val_loss: 0.4989 - val_binary_accuracy: 0.8222
Epoch 3/20
625/625 [==============================] - 3s 4ms/step - loss: 0.4665 - binary_accuracy: 0.8349 - val_loss: 0.4203 - val_binary_accuracy: 0.8476
Epoch 4/20
625/625 [==============================] - 3s 4ms/step - loss: 0.3920 - binary_accuracy: 0.8582 - val_loss: 0.3737 - val_binary_accuracy: 0.8610
Epoch 5/20
625/625 [==============================] - 3s 4ms/step - loss: 0.3443 - binary_accuracy: 0.8757 - val_loss: 0.3448 - val_binary_accuracy: 0.8686
Epoch 6/20
625/625 [==============================] - 3s 4ms/step - loss: 0.3107 - binary_accuracy: 0.8876 - val_loss: 0.3259 - val_binary_accuracy: 0.8718
Epoch 7/20
625/625 [==============================] - 3s 4ms/step - loss: 0.2866 - binary_accuracy: 0.8981 - val_loss: 0.3127 - val_binary_accuracy: 0.8726
Epoch 8/20
625/625 [==============================] - 3s 4ms/step - loss: 0.2651 - binary_accuracy: 0.9028 - val_loss: 0.3031 - val_binary_accuracy: 0.8752
Epoch 9/20
625/625 [==============================] - 3s 4ms/step - loss: 0.2492 - binary_accuracy: 0.9112 - val_loss: 0.2962 - val_binary_accuracy: 0.8778
Epoch 10/20
625/625 [==============================] - 3s 4ms/step - loss: 0.2336 - binary_accuracy: 0.9156 - val_loss: 0.2916 - val_binary_accuracy: 0.8790
Epoch 11/20
625/625 [==============================] - 3s 4ms/step - loss: 0.2208 - binary_accuracy: 0.9216 - val_loss: 0.2886 - val_binary_accuracy: 0.8802
Epoch 12/20
625/625 [==============================] - 3s 4ms/step - loss: 0.2091 - binary_accuracy: 0.9246 - val_loss: 0.2865 - val_binary_accuracy: 0.8816
Epoch 13/20
625/625 [==============================] - 3s 4ms/step - loss: 0.1992 - binary_accuracy: 0.9286 - val_loss: 0.2862 - val_binary_accuracy: 0.8820
Epoch 14/20
625/625 [==============================] - 3s 4ms/step - loss: 0.1901 - binary_accuracy: 0.9350 - val_loss: 0.2857 - val_binary_accuracy: 0.8822
Epoch 15/20
625/625 [==============================] - 3s 4ms/step - loss: 0.1808 - binary_accuracy: 0.9380 - val_loss: 0.2868 - val_binary_accuracy: 0.8824
Epoch 16/20
625/625 [==============================] - 3s 4ms/step - loss: 0.1719 - binary_accuracy: 0.9431 - val_loss: 0.2880 - val_binary_accuracy: 0.8828
Epoch 17/20
625/625 [==============================] - 3s 4ms/step - loss: 0.1640 - binary_accuracy: 0.9444 - val_loss: 0.2902 - val_binary_accuracy: 0.8824
Epoch 18/20
625/625 [==============================] - 3s 4ms/step - loss: 0.1581 - binary_accuracy: 0.9458 - val_loss: 0.2930 - val_binary_accuracy: 0.8838
Epoch 19/20
625/625 [==============================] - 3s 4ms/step - loss: 0.1497 - binary_accuracy: 0.9498 - val_loss: 0.2962 - val_binary_accuracy: 0.8820
Epoch 20/20
625/625 [==============================] - 3s 4ms/step - loss: 0.1421 - binary_accuracy: 0.9545 - val_loss: 0.2997 - val_binary_accuracy: 0.8810
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[38]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># loss, accuracy</span>
<span class="n">model_1</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">train_ds</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
625/625 [==============================] - 1s 1ms/step - loss: 0.1292 - binary_accuracy: 0.9584
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[38]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[0.1292424201965332, 0.9584000110626221]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[39]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># loss, accuracy</span>
<span class="n">model_1</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_ds</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
782/782 [==============================] - 1s 1ms/step - loss: 0.3335 - binary_accuracy: 0.8683
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[39]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[0.33350175619125366, 0.8682799935340881]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[40]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">plot_history</span><span class="p">(</span><span class="n">history_dict_0</span><span class="p">,</span> <span class="n">history_dict_1</span><span class="p">):</span>

    <span class="n">acc_0</span> <span class="o">=</span> <span class="n">history_dict_0</span><span class="p">[</span><span class="s2">&quot;binary_accuracy&quot;</span><span class="p">]</span>
    <span class="n">val_acc_0</span> <span class="o">=</span> <span class="n">history_dict_0</span><span class="p">[</span><span class="s2">&quot;val_binary_accuracy&quot;</span><span class="p">]</span>
    <span class="n">loss_0</span> <span class="o">=</span> <span class="n">history_dict_0</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span>
    <span class="n">val_loss_0</span> <span class="o">=</span> <span class="n">history_dict_0</span><span class="p">[</span><span class="s2">&quot;val_loss&quot;</span><span class="p">]</span>

    <span class="n">acc_1</span> <span class="o">=</span> <span class="n">history_dict_1</span><span class="p">[</span><span class="s2">&quot;binary_accuracy&quot;</span><span class="p">]</span>
    <span class="n">val_acc_1</span> <span class="o">=</span> <span class="n">history_dict_1</span><span class="p">[</span><span class="s2">&quot;val_binary_accuracy&quot;</span><span class="p">]</span>
    <span class="n">loss_1</span> <span class="o">=</span> <span class="n">history_dict_1</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span>
    <span class="n">val_loss_1</span> <span class="o">=</span> <span class="n">history_dict_1</span><span class="p">[</span><span class="s2">&quot;val_loss&quot;</span><span class="p">]</span>

    <span class="n">epochs</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">acc_0</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">loss_0</span><span class="p">,</span> <span class="s2">&quot;ko&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training loss 0&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_loss_0</span><span class="p">,</span> <span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Validation loss 0&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">loss_1</span><span class="p">,</span> <span class="s2">&quot;ro&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training loss 1&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_loss_1</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Validation loss 1&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Training and validation loss&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epochs&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">acc_0</span><span class="p">,</span> <span class="s2">&quot;ko&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training acc 0&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_acc_0</span><span class="p">,</span> <span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Validation acc 0&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">acc_1</span><span class="p">,</span> <span class="s2">&quot;ro&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training acc 1&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_acc_1</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Validation acc 1&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Training and validation accuracy&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epochs&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="n">plot_history</span><span class="p">(</span><span class="n">history_0</span><span class="o">.</span><span class="n">history</span><span class="p">,</span> <span class="n">history_1</span><span class="o">.</span><span class="n">history</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../_images/notebooks_tensorflow_texto_1-01_clasificacion_de_texto_usando_TextVectorization_56_0.png" src="../../../_images/notebooks_tensorflow_texto_1-01_clasificacion_de_texto_usando_TextVectorization_56_0.png" />
</div>
</div>
</div>
<div class="section" id="Modelo-en-productivo">
<h2>Modelo en productivo<a class="headerlink" href="#Modelo-en-productivo" title="Enlazar permanentemente con este título">¶</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[41]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Es posibles crear un modleo que combine los</span>
<span class="c1"># pasos anteriores.</span>
<span class="c1">#</span>
<span class="n">export_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">vectorize_layer</span><span class="p">,</span>
        <span class="n">model_0</span><span class="p">,</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">),</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">export_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
    <span class="n">loss</span><span class="o">=</span><span class="n">losses</span><span class="o">.</span><span class="n">BinaryCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
<span class="p">)</span>

<span class="c1">#</span>
<span class="c1"># Se ejecuta el modelo empaquetado sobre los</span>
<span class="c1"># datos de prueba originales (sin preprocesar).</span>
<span class="c1"># La funcion evaluate retorna la perdida y</span>
<span class="c1"># precision</span>
<span class="c1">#</span>
<span class="n">export_model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">raw_test_ds</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
782/782 [==============================] - 21s 26ms/step - loss: 0.3491 - accuracy: 0.8648
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[41]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[0.35619601607322693, 0.8643199801445007]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[42]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">examples</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;The movie was great!&quot;</span><span class="p">,</span>
    <span class="s2">&quot;The movie was okay.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;The movie was terrible...&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">export_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">examples</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[42]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([[0.687941  ],
       [0.41689426],
       [0.3150716 ]], dtype=float32)
</pre></div></div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Derechos de autor 2019, Juan D. Velasquez.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-XXXXXXX-1', 'auto');
    
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>